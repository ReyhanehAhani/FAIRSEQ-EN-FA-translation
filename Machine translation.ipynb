{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece sacremoses -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preview(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    print(f\"Total lines in {file_path}: {len(lines)}\")\n",
    "    print(\"First three lines:\", lines[:3])\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "file_path = '/content/NLP_CA5_raw.data/en-fa.txt (1).zip'\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preview(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    print(f\"Total lines in {file_path}: {len(lines)}\")\n",
    "    print(\"First three lines:\", lines[:3])\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_en = '/content/MIZAN.en-fa.en'\n",
    "file_path_fa = '/content/MIZAN.en-fa.fa'\n",
    "english_lines = load_and_preview(file_path_en)\n",
    "farsi_lines = load_and_preview(file_path_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_histogram(lines, language):\n",
    "    token_counts = [len(line.split()) for line in lines]\n",
    "    plt.hist(token_counts, bins=30, alpha=0.7)\n",
    "    plt.title(f'Token count histogram for {language}')\n",
    "    plt.xlabel('Number of tokens')\n",
    "    plt.ylabel('Number of lines')\n",
    "    plt.show()\n",
    "    return token_counts\n",
    "\n",
    "en_token_counts = tokenize_and_histogram(english_lines, 'English')\n",
    "fa_token_counts = tokenize_and_histogram(farsi_lines, 'Farsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(en_lines, fa_lines, en_token_counts, fa_token_counts):\n",
    "    filtered_en = []\n",
    "    filtered_fa = []\n",
    "    for en, fa, en_count, fa_count in zip(en_lines, fa_lines, en_token_counts, fa_token_counts):\n",
    "        if 10 <= fa_count <= 50:\n",
    "            filtered_en.append(en)\n",
    "            filtered_fa.append(fa)\n",
    "    print(f\"Number of rows after filtering: {len(filtered_en)}\")\n",
    "    return filtered_en, filtered_fa\n",
    "\n",
    "filtered_english, filtered_farsi = filter_data(english_lines, farsi_lines, en_token_counts, fa_token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_and_split(en_data, fa_data, seed=42):\n",
    "    en_data, fa_data = shuffle(en_data, fa_data, random_state=seed)\n",
    "    train_en, valid_en, test_en = en_data[:500000], en_data[500000:505000], en_data[505000:515000]\n",
    "    train_fa, valid_fa, test_fa = fa_data[:500000], fa_data[500000:505000], fa_data[505000:515000]\n",
    "    return train_en, valid_en, test_en, train_fa, valid_fa, test_fa\n",
    "\n",
    "train_en, valid_en, test_en, train_fa, valid_fa, test_fa = shuffle_and_split(filtered_english, filtered_farsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_files(data, file_name):\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(data)\n",
    "\n",
    "output_folder = '/content/'\n",
    "write_to_files(train_en, f'{output_folder}train.en')\n",
    "write_to_files(valid_en, f'{output_folder}valid.en')\n",
    "write_to_files(test_en, f'{output_folder}test.en')\n",
    "write_to_files(train_fa, f'{output_folder}train.fa')\n",
    "write_to_files(valid_fa, f'{output_folder}valid.fa')\n",
    "write_to_files(test_fa, f'{output_folder}test.fa')\n",
    "\n",
    "print(\"Data processing complete and files saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/pytorch/fairseq\n",
    "!cd fairseq && pip install --editable ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpe_tokenizer(input, model_prefix, vocab = 10000):\n",
    "  spm.SentencePieceTrainer.Train(f'--input={input} --model_prefix={model_prefix} --vocab_size={vocab} --model_type=bpe')\n",
    "\n",
    "bpe_tokenizer('/content/train.fa', 'bpe_persian')\n",
    "bpe_tokenizer('/content/train.en', 'bpe_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "def encode_file(sp_model, input_file, output_file):\n",
    "    sp = spm.SentencePieceProcessor(model_file=sp_model)\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for line in infile:\n",
    "            encoded_line = sp.encode(line, out_type=str)\n",
    "            outfile.write(' '.join(encoded_line) + '\\n')\n",
    "\n",
    "# Encode files\n",
    "encode_file('/content/bpe_persian.model', '/content/train.fa', '/content/train.bpe.fa')\n",
    "encode_file('/content/bpe_persian.model', '/content/valid.fa', '/content/valid.bpe.fa')\n",
    "encode_file('/content/bpe_persian.model', '/content/test.fa', '/content/test.bpe.fa')\n",
    "\n",
    "encode_file('/content/bpe_english.model', '/content/train.en', '/content/train.bpe.en')\n",
    "encode_file('/content/bpe_english.model', '/content/valid.en', '/content/valid.bpe.en')\n",
    "encode_file('/content/bpe_english.model', '/content/test.en', '/content/test.bpe.en')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Data Using Fairseq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-preprocess --source-lang fa --target-lang en \\\n",
    "    --trainpref /content/train.bpe --validpref /content/valid.bpe --testpref /content/test.bpe \\\n",
    "    --destdir /content/data-bin/ \\\n",
    "    --nwordssrc 10000 --nwordstgt 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training LSTM Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 fairseq-train /content/data-bin/ \\\n",
    "    --arch lstm --encoder-layers 6 --decoder-layers 6 \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.2 \\\n",
    "    --lr 0.001 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-7 \\\n",
    "    --dropout 0.1 --weight-decay 0.0001 \\\n",
    "    --max-tokens 1000 --batch-size 32 \\\n",
    "    --save-dir /content/checkpoints/ \\\n",
    "    --max-epoch 5 --save-interval 1 --keep-best-checkpoints 1 \\\n",
    "    --no-epoch-checkpoints \\\n",
    "    --tensorboard-logdir /content/tensorboard_logs/ \\\n",
    "    --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '/content/tensorboard_logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 fairseq-train /content/data-bin/ \\\n",
    "    --arch transformer --encoder-layers 6 --decoder-layers 6 \\\n",
    "    --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' \\\n",
    "    --lr 0.001 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-7 \\\n",
    "    --dropout 0.1 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.2 \\\n",
    "    --max-tokens 1000 \\\n",
    "    --save-dir /content/checkpoints_transformer/ \\\n",
    "    --max-epoch 5 --save-interval 1 --keep-best-checkpoints 1 \\\n",
    "    --tensorboard-logdir /content/tensorboard_logs_transformer/ \\\n",
    "    --fp16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/tensorboard_logs_transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fourth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unbabel-comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-generate /content/data-bin/ \\\n",
    "    --path /content/checkpoints/checkpoint_best.pt \\\n",
    "    --batch-size 64 --beam 5 \\\n",
    "    --remove-bpe \\\n",
    "    > lstm_output.txt\n",
    "\n",
    "!fairseq-generate /content/data-bin/ \\\n",
    "    --path /content/checkpoints_transformer/checkpoint_best.pt \\\n",
    "    --batch-size 64 --beam 5 \\\n",
    "    --remove-bpe \\\n",
    "    > transformer_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "model_path = download_model(\"wmt20-comet-da\")\n",
    "comet_model = load_from_checkpoint(model_path)\n",
    "\n",
    "def evaluate_with_comet(source_file, target_file, hypothesis_file, comet_model):\n",
    "    with open(source_file, 'r') as src, open(target_file, 'r') as tgt, open(hypothesis_file, 'r') as hyp:\n",
    "        sources = src.readlines()\n",
    "        targets = tgt.readlines()\n",
    "        hypotheses = hyp.readlines()\n",
    "\n",
    "    data = [{\"src\": src.strip(), \"mt\": hyp.strip(), \"ref\": tgt.strip()}\n",
    "            for src, hyp, tgt in zip(sources, hypotheses, targets)]\n",
    "\n",
    "\n",
    "    scores = comet_model.predict(data, batch_size=32, gpus=1)\n",
    "    return scores\n",
    "\n",
    "# Example of procced\n",
    "comet_scores_lstm = evaluate_with_comet('/content/test.en', '/content/test.fa', 'lstm_output.txt', comet_model)\n",
    "comet_scores_transformer = evaluate_with_comet('/content/test.en', '/content/test.fa', 'transformer_output.txt', comet_model)\n",
    "\n",
    "print(\"COMET scores for LSTM model:\", comet_scores_lstm)\n",
    "print(\"COMET scores for Transformer model:\", comet_scores_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_scores_lstm['system_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_scores_transformer['system_score']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
